# ðŸ§  Generative Adversarial Network for Floor Plan Generation ðŸ 

A PyTorch-based project that trains a **Generative Adversarial Network (GAN)** to generate architectural floor plans from grayscale or black-and-white input sketches. Designed to be lightweight and trainable on systems with limited resources (like 8GB RAM and GTX 1650 GPU), it uses a carefully selected 10K paired dataset from a larger collection of 80K images.

---

## ðŸš§ Project Highlights

- ðŸ” **Paired Dataset**: Input and output images matched by filename in two separate folders
- ðŸ§  **Custom GAN**: Includes both Generator (U-Net style) and PatchGAN Discriminator
- ðŸ’¾ **Model Checkpointing**: Automatically saves generator and discriminator
- ðŸ§ª **Inference-Ready**: Easily generate new floor plans using your trained model
- ðŸ› ï¸ **Optimized Training**: Configurable for shorter training cycles


---

## âœ¨ Features

- âœ… Trainable GAN using paired input/output images
- âœ… Automatically preprocesses images (resized, B/W conversion)
- âœ… Save and reuse trained generator for inference
- âœ… Lightweight and runs comfortably on mid-range systems
- âœ… Custom dataset support â€” just match filenames!

---

## ðŸ—‚ï¸ Folder Structure

```
project_root/ 
â”œâ”€â”€ saved_models/ # Contains generator.pth, discriminator.pth â”‚ â”œâ”€â”€ train.py # Script to train GAN â”œâ”€â”€ run.py # Script to generate output from new input â”œâ”€â”€ requirements.txt # List of dependencies â””â”€â”€ README.md # You're here!

```
---

## ðŸ–¼ï¸ Sample Workflow

### Input:
* [Input Example](assets/99_input.png)

### Generated Output:  
*  [Output Example](assets/99_output.png)

---

## ðŸš€ Getting Started

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/varunnnnsonii/Generative-Adversarial-Network-Floor-Plan.git
cd Generative-Adversarial-Network-Floor-Plan

pip install -r requirements.txt

python train.py

python run.py
```
---
## ðŸ’¾ Save & Load Models
### Models are saved /:
* generator_final.pth
* discriminator_final.pth

### Use these with run.py to generate outputs for new input images.
---

## ðŸ¤– Model Architecture

- **Generator:** U-Net style convolutional network
- **Discriminator:** PatchGAN (CNN-based classifier)

---

## ðŸ› ï¸ Requirements

- Python 3.8+
- PyTorch
- torchvision
- Pillow
- tqdm

---

## âœï¸ Author

**Varun D Soni**  
ðŸ”— [GitHub](https://github.com/varunnnnsonii)  
ðŸ“« varun271203@gmail.com

---

## ðŸŒŸ Star this repo if it helped you!
### If this project helped you or inspired you, donâ€™t forget to:

* â­ Star the repo

* ðŸ´ Fork it

* 
ðŸ› Raise an issue or contribute!




### âœ… Next Steps

- Add `requirements.txt` using:
  ```bash
  pip freeze > requirements.txt
  ```
- Add your actual **input/output example images** in the repo (or upload them via GitHub â†’ "Upload files")
- Replace the `![Input]` and `![Output]` image URLs with GitHub image links (once uploaded)
- Commit and push the updated `README.md`:
  ```bash
  git add README.md
  git commit -m "Added beautiful README ðŸ’«"
  git push
  ```

---
### Thatâ€™s it! When you go to your GitHub repo, you'll see your new professional README automatically rendered âœ¨
